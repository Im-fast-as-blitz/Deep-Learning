{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed09a27-1970-4d6d-8503-fddc70879c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T11:37:25.710768Z",
     "iopub.status.busy": "2024-02-28T11:37:25.709994Z",
     "iopub.status.idle": "2024-02-28T11:37:35.486741Z",
     "shell.execute_reply": "2024-02-28T11:37:35.485869Z",
     "shell.execute_reply.started": "2024-02-28T11:37:25.710711Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch import nn\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torchtext.vocab import vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5415b983-e1ba-4287-ac17-0d03e45937af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T11:37:35.488694Z",
     "iopub.status.busy": "2024-02-28T11:37:35.488005Z",
     "iopub.status.idle": "2024-02-28T11:37:35.584449Z",
     "shell.execute_reply": "2024-02-28T11:37:35.583389Z",
     "shell.execute_reply.started": "2024-02-28T11:37:35.488655Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4770628b-dcce-4826-8b0b-f4acb0daf765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T11:37:35.586761Z",
     "iopub.status.busy": "2024-02-28T11:37:35.586129Z",
     "iopub.status.idle": "2024-02-28T11:37:35.613226Z",
     "shell.execute_reply": "2024-02-28T11:37:35.612326Z",
     "shell.execute_reply.started": "2024-02-28T11:37:35.586722Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LangDataset(Dataset):\n",
    "    def __init__(self, source_file_de, vocab_de, max_len, source_file_en=None, vocab_en=None, cut=False):\n",
    "        self.text_de = []\n",
    "        with open(source_file_de) as file:\n",
    "            for line in file.readlines():\n",
    "                self.text_de.append(np.array(line.split(' ')))\n",
    "        self.text_de = np.array(self.text_de, dtype=type(self.text_de[0]))\n",
    "        if cut:\n",
    "            new_ind = np.random.choice(self.text_de.shape[0], self.text_de.shape[0] // 2)\n",
    "            self.text_de = self.text_de[new_ind]\n",
    "        self.text_en = None\n",
    "        \n",
    "        self.specials = ['<pad>', '<bos>', '<eos>', '<unk>']\n",
    "        \n",
    "        self.vocab_de = vocab_de\n",
    "        self.itos_de = self.vocab_de.get_itos()\n",
    "        self.vocab_en = None\n",
    "        self.itos_en = None\n",
    "        \n",
    "        self.pad_index = self.vocab_de['<pad>']\n",
    "        self.bos_index = self.vocab_de['<bos>']\n",
    "        self.eos_index = self.vocab_de['<eos>']\n",
    "        self.unk_index = self.vocab_de['<unk>']\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        if source_file_en is not None:\n",
    "            self.text_en = []\n",
    "            with open(source_file_en) as file:\n",
    "                for line in file.readlines():\n",
    "                    self.text_en.append(np.array(line.split(' ')))\n",
    "            self.text_en = np.array(self.text_en, dtype=type(self.text_en[0]))\n",
    "            if cut:\n",
    "                self.text_en = self.text_en[new_ind]\n",
    "            self.vocab_en = vocab_en\n",
    "            self.itos_en = self.vocab_en.get_itos()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_de)\n",
    "\n",
    "    def str_to_idx(self, text, lng='de'):\n",
    "        if lng == 'de':\n",
    "            return [self.vocab_de[word] for word in text]\n",
    "        return [self.vocab_en[word] for word in text]\n",
    "\n",
    "    def idx_to_str(self, idx, lng='de'):\n",
    "        if lng == 'de':\n",
    "            return [self.itos_de[index] for index in idx]\n",
    "        return [self.itos_en[index] for index in idx]\n",
    "\n",
    "    def encode(self, chars, lng='de'):\n",
    "        chars = ['<bos>'] + list(chars) + ['<eos>']\n",
    "        return self.str_to_idx(chars, lng)\n",
    "\n",
    "    def decode(self, idx, lng='de'):\n",
    "        chars = self.idx_to_str(idx, lng)\n",
    "        return ' '.join(char for char in chars if char not in self.specials)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        encoded_de = self.encode(self.text_de[item])\n",
    "        \n",
    "        if self.text_en is not None:\n",
    "            encoded_en = self.encode(self.text_en[item], lng='en')\n",
    "            return encoded_de, encoded_en\n",
    "        \n",
    "        return encoded_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4606ac48-f56d-41fd-8da9-b6fee8037bcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T12:02:34.358402Z",
     "iopub.status.busy": "2024-02-28T12:02:34.357379Z",
     "iopub.status.idle": "2024-02-28T12:02:34.383917Z",
     "shell.execute_reply": "2024-02-28T12:02:34.383149Z",
     "shell.execute_reply.started": "2024-02-28T12:02:34.358355Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_epoch(model, optimizer, criterion, train_loader, tqdm_desc):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for de_text, en_text in tqdm(train_loader, desc=tqdm_desc):\n",
    "        de_text = de_text.to(device)\n",
    "        en_text = en_text.to(device)\n",
    "        \n",
    "        tgt_input = en_text[:, :-1]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(de_text, tgt_input)\n",
    "        src_mask = src_mask.to(device)\n",
    "        tgt_mask = tgt_mask.to(device)\n",
    "        src_padding_mask = src_padding_mask.to(device)\n",
    "        tgt_padding_mask = tgt_padding_mask.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(de_text, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        \n",
    "        tgt_out = en_text[:, 1:]\n",
    "        loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(list(train_loader))\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_epoch(model, criterion, test_loader, tqdm_desc):\n",
    "    test_loss = 0.0\n",
    "    model.eval()\n",
    "    \n",
    "    for de_text, en_text in tqdm(test_loader, desc=tqdm_desc):\n",
    "        de_text = de_text.to(device)\n",
    "        en_text = en_text.to(device)\n",
    "        \n",
    "        tgt_input = en_text[:, :-1]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(de_text, tgt_input)\n",
    "        src_mask = src_mask.to(device)\n",
    "        tgt_mask = tgt_mask.to(device)\n",
    "        src_padding_mask = src_padding_mask.to(device)\n",
    "        tgt_padding_mask = tgt_padding_mask.to(device)\n",
    "        \n",
    "        logits = model(de_text, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        \n",
    "        tgt_out = en_text[:, 1:]\n",
    "        loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(list(test_loader))\n",
    "    return test_loss\n",
    "\n",
    "\n",
    "def train(model, optimizer, scheduler, criterion, train_loader, test_loader, num_epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = training_epoch(\n",
    "            model, optimizer, criterion, train_loader,\n",
    "            tqdm_desc=f'Training {epoch}/{num_epochs}'\n",
    "        )\n",
    "        test_loss = validation_epoch(\n",
    "            model, criterion, test_loader,\n",
    "            tqdm_desc=f'Validating {epoch}/{num_epochs}'\n",
    "        )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        train_losses += [train_loss]\n",
    "        test_losses += [test_loss]\n",
    "        # torch.save(model.state_dict(), \"weights.pt\")\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask).to(device)\n",
    "    tokens = torch.tensor([start_symbol]).unsqueeze(0).to(device)\n",
    "    for i in range(max_len - 1):\n",
    "        tgt_mask = generate_square_subsequent_mask(tokens.shape[1]).type(torch.bool).to(device)\n",
    "        \n",
    "        out = model.decode(tokens, memory, tgt_mask)\n",
    "        prob = model.linear(out[:, -1])\n",
    "        new_token = prob.argmax(dim=1)\n",
    "\n",
    "        tokens = torch.cat([tokens, new_token.unsqueeze(0)], dim=1)\n",
    "        if new_token.item() == en_vocab['<eos>']:\n",
    "            break\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def translate(model, src, start_symbol, vocab):\n",
    "    model.eval()\n",
    "    result = \"\"\n",
    "    \n",
    "    for line in tqdm(src):\n",
    "        line = torch.Tensor(line).unsqueeze(0).to(device)\n",
    "        max_len = line.shape[1]\n",
    "        src_mask = torch.zeros((line.shape[1], line.shape[1])).type(torch.bool).to(device)\n",
    "        \n",
    "        trans_line = greedy_decode(model, line, src_mask, max_len + 5, start_symbol)\n",
    "        \n",
    "        result += vocab.decode(trans_line.reshape(-1), lng='en') + '\\n'\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz))) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[1]\n",
    "    tgt_seq_len = tgt.shape[1]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len)).type(torch.bool)\n",
    "    PAD_IDX = 0\n",
    "    src_padding_mask = (src == PAD_IDX)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(torch.Tensor(src_sample))\n",
    "        tgt_batch.append(torch.Tensor(tgt_sample))\n",
    "\n",
    "    return pad_sequence(src_batch, batch_first=True, padding_value=0).type(torch.LongTensor), pad_sequence(tgt_batch, batch_first=True, padding_value=0).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "839f3b48-1421-459f-946e-da4ab965fd6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T11:37:35.659707Z",
     "iopub.status.busy": "2024-02-28T11:37:35.658744Z",
     "iopub.status.idle": "2024-02-28T11:37:35.695641Z",
     "shell.execute_reply": "2024-02-28T11:37:35.694760Z",
     "shell.execute_reply.started": "2024-02-28T11:37:35.659666Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_vocab(files: list, t=1):\n",
    "    text = []\n",
    "    max_len = 0\n",
    "    for file_source in files:\n",
    "        with open(file_source) as file:\n",
    "            for line in file.readlines():\n",
    "                line = line.replace('\\n', '')\n",
    "                \n",
    "                new_line = line.split(' ')\n",
    "                text.append(new_line)\n",
    "                if len(new_line) > max_len:\n",
    "                    max_len = len(new_line)\n",
    "            \n",
    "    vocab = build_vocab_from_iterator(text, specials=['<pad>', '<bos>', '<eos>', '<unk>'], min_freq=t)\n",
    "    vocab.set_default_index(vocab['<unk>'])\n",
    "    return vocab, max_len + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdef9970-aa52-4ff0-bd7a-071eb5c27178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T11:37:35.698071Z",
     "iopub.status.busy": "2024-02-28T11:37:35.696893Z",
     "iopub.status.idle": "2024-02-28T11:37:35.729386Z",
     "shell.execute_reply": "2024-02-28T11:37:35.728404Z",
     "shell.execute_reply.started": "2024-02-28T11:37:35.698031Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyEmbedder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, pad_id, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=emb_size, padding_idx=pad_id)\n",
    "        \n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2) * np.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        pos_embedding = torch.zeros((max_len, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "        \n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        embeddings = self.embedding(tokens.long()) * np.sqrt(self.emb_size)\n",
    "        out = embeddings + self.pos_embedding[:, :embeddings.size(1)]\n",
    "        return self.dropout(out)\n",
    "\n",
    "    \n",
    "class MyTransformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, nhead, pad_id, max_len, d_model=512, num_enc_lay=3, num_dec_lay=3, dim_feedforward=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding_src = MyEmbedder(src_vocab, d_model, pad_id)\n",
    "        self.embedding_trg = MyEmbedder(trg_vocab, d_model, pad_id)\n",
    "        \n",
    "        self.trans = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_enc_lay,\n",
    "                                       num_decoder_layers=num_dec_lay, dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout, batch_first=True)\n",
    "        self.linear = nn.Linear(d_model, trg_vocab)\n",
    "        \n",
    "        self.nhead = nhead\n",
    "        \n",
    "    def forward(self, src, trg, src_mask, trg_mask, src_padding_mask, trg_padding_mask, memory_key_padding_mask):\n",
    "        embeddings_src = self.embedding_src(src)\n",
    "        embeddings_trg = self.embedding_trg(trg)\n",
    "        \n",
    "        trans_out = self.trans(embeddings_src, embeddings_trg, src_mask, trg_mask, None,\n",
    "                                src_padding_mask, trg_padding_mask, memory_key_padding_mask)\n",
    "        return self.linear(trans_out)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.trans.encoder(self.embedding_src(src), src_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        return self.trans.decoder(self.embedding_trg(tgt), memory, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcaaafe9-0adc-4eb0-96f6-dc51ee410d79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T12:03:01.924492Z",
     "iopub.status.busy": "2024-02-28T12:03:01.923697Z",
     "iopub.status.idle": "2024-02-28T12:03:05.237716Z",
     "shell.execute_reply": "2024-02-28T12:03:05.236984Z",
     "shell.execute_reply.started": "2024-02-28T12:03:01.924440Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab, max_en = create_vocab(['train.de-en.en'], t=1)\n",
    "de_vocab, max_de = create_vocab(['train.de-en.de'], t=8)\n",
    "\n",
    "max_str_size = max(max_en, max_de)\n",
    "max_str_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62f80a43-07da-4771-8a92-4383c92cd2f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T12:03:05.239563Z",
     "iopub.status.busy": "2024-02-28T12:03:05.238968Z",
     "iopub.status.idle": "2024-02-28T12:03:07.997689Z",
     "shell.execute_reply": "2024-02-28T12:03:07.996746Z",
     "shell.execute_reply.started": "2024-02-28T12:03:05.239529Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_Dataset = LangDataset('train.de-en.de', de_vocab, max_str_size, 'train.de-en.en', en_vocab, cut=False)\n",
    "\n",
    "val_Dataset = LangDataset('val.de-en.de', de_vocab, max_str_size, 'val.de-en.en', en_vocab)\n",
    "\n",
    "test_Dataset = LangDataset('test1.de-en.de', de_vocab, max_str_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6899828-9cb3-47c1-bb30-afb1b15d4568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T12:03:08.000406Z",
     "iopub.status.busy": "2024-02-28T12:03:07.999472Z",
     "iopub.status.idle": "2024-02-28T12:03:08.011862Z",
     "shell.execute_reply": "2024-02-28T12:03:08.011015Z",
     "shell.execute_reply.started": "2024-02-28T12:03:08.000364Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_Dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "val_loader = DataLoader(val_Dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "test_de_loader = DataLoader(test_Dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc1b9be9-264d-45ae-8534-ff739feb4c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T12:03:08.013607Z",
     "iopub.status.busy": "2024-02-28T12:03:08.013122Z",
     "iopub.status.idle": "2024-02-28T12:03:09.190622Z",
     "shell.execute_reply": "2024-02-28T12:03:09.189818Z",
     "shell.execute_reply.started": "2024-02-28T12:03:08.013568Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "model = MyTransformer(len(de_vocab), len(en_vocab), 8, train_Dataset.pad_index, max_str_size, 512, 3, 3, 512, 0.1)\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=train_Dataset.pad_index, label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a8855-0569-436a-9490-bfc846458a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T12:03:09.192214Z",
     "iopub.status.busy": "2024-02-28T12:03:09.191684Z",
     "iopub.status.idle": "2024-02-28T15:03:19.739063Z",
     "shell.execute_reply": "2024-02-28T15:03:19.738228Z",
     "shell.execute_reply.started": "2024-02-28T12:03:09.192157Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses, test_losses, train_accuracies, test_accuracies = train(\n",
    "    model, optimizer, None, criterion, train_loader, val_loader, num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4097e64d-e46f-405b-b369-9f9133b66735",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T12:02:54.397105Z",
     "iopub.status.busy": "2024-02-28T12:02:54.395907Z",
     "iopub.status.idle": "2024-02-28T12:02:54.529906Z",
     "shell.execute_reply": "2024-02-28T12:02:54.529061Z",
     "shell.execute_reply.started": "2024-02-28T12:02:54.397053Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import gc\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d84749e-6725-4bae-8fde-f81b1dd167fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:03:27.819724Z",
     "iopub.status.busy": "2024-02-28T15:03:27.819011Z",
     "iopub.status.idle": "2024-02-28T15:07:53.206779Z",
     "shell.execute_reply": "2024-02-28T15:07:53.205888Z",
     "shell.execute_reply.started": "2024-02-28T15:03:27.819688Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8ad16d7fed4e3f96a6fa67b58ffea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = translate(model, test_Dataset, en_vocab['<bos>'], train_Dataset)\n",
    "with open('test.de-en.en', 'w') as file:\n",
    "    file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf290f0-6c19-4f4e-ad11-486700485a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
